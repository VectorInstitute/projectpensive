{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27253db5",
   "metadata": {},
   "source": [
    "# Diversity in Reddit Comments\n",
    "\n",
    "This notebook implements the Greedy Selection Algorithm that was  the [Improving Reccomendation Diversity](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.8.5232&rep=rep1&type=pdf) research paper. The dataset can be found [here](https://www.kaggle.com/sherinclaudia/sarcastic-comments-on-reddit)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5425d0ce",
   "metadata": {},
   "source": [
    "## Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fab1c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import io\n",
    "import csv\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f975f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sarcasm Dataset\n",
    "df_m = pd.read_csv('../../civility/recommender/train-balanced-sarcasm-processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75649e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all comments to a list\n",
    "corpus = df_m['comment'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bf1dfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for computing embeddings:281.16767168045044\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "embedder = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Embed each comment\n",
    "import time\n",
    "start_time = time.time()\n",
    "sarcasm_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
    "end_time = time.time()\n",
    "print(\"Time for computing embeddings:\"+ str(end_time-start_time) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cd82fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add vector embeddings as column in df\n",
    "vectors = []\n",
    "for vector in sarcasm_embeddings:\n",
    "    vectors.append(list(vector.cpu().numpy()))\n",
    "    \n",
    "df_m['vector'] = vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0167184",
   "metadata": {},
   "source": [
    "## Saving Embeddings to .pt File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0f4c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectors\n",
    "torch.save(sarcasm_embeddings, 'sarcasm_embeddings.pt')\n",
    "# Load Vectors from file \n",
    "# sarcasm_embeddings = torch.load('sarcasm_embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0006482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "outfile = open('sarcasm_metadata.csv','w')\n",
    "out = csv.writer(outfile)\n",
    "out.writerows(map(lambda x: [x], corpus))\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc5b8f7",
   "metadata": {},
   "source": [
    "## Example Query Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2c39423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Trump has improved the economy so much!\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "Trump will make it better. (Score: 0.6741)\n",
      "Well thank goodness Trump is going to make it great again. (Score: 0.6713)\n",
      "Because Donald Trump is going to make America great again. (Score: 0.6546)\n",
      "BUT TRUMP SAID HE WAS GONNA MAKE AMERICA GREAT AGAIN! (Score: 0.6480)\n",
      "But Trump can make all of America great again! (Score: 0.6452)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Xbox is much better than PS4\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "No, because the xbox one is soooo much better than the ps4 (Score: 0.9228)\n",
      "but xbox has the highest quality pixels, so it should be better than ps4, right? (Score: 0.8895)\n",
      "Xbox or PS4 (Score: 0.8632)\n",
      "Ayy, better than Xbox 7 and PS5 (Score: 0.8622)\n",
      "Ps4 or Xbox (Score: 0.8430)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Taliban bombs school\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "Nah, the Pakistani Taliban shoot school girls for going to school because of the invasion of Iraq. (Score: 0.7269)\n",
      "And bomb Afghani schools (Score: 0.7146)\n",
      "especially when the taliban bomb schools and murder schoolchildren because who wants education much less educated girls... (Score: 0.6726)\n",
      "also read up on pre-taliban Afghanistan (Score: 0.6186)\n",
      "Thanks Taliban! (Score: 0.6178)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Run this for example queries\n",
    "This script outputs for various queries the top 5 most similar sentences in the corpus.\n",
    "\"\"\"\n",
    "# Query sentences:\n",
    "queries = ['Trump has improved the economy so much!', 'Xbox is much better than PS4', 'Taliban bombs school']\n",
    "\n",
    "\n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "top_k = min(5, len(corpus))\n",
    "for query in queries:\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, sarcasm_embeddings)[0]\n",
    "    top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "    print(\"\\n\\n======================\\n\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "    for score, idx in zip(top_results[0], top_results[1]):\n",
    "        print(corpus[idx], \"(Score: {:.4f})\".format(score))\n",
    "\n",
    "    \"\"\"\n",
    "    # Alternatively, we can also use util.semantic_search to perform cosine similarty + topk\n",
    "    hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=5)\n",
    "    hits = hits[0]      #Get the hits for the first query\n",
    "    for hit in hits:\n",
    "        print(corpus[hit['corpus_id']], \"(Score: {:.4f})\".format(hit['score']))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2121858",
   "metadata": {},
   "source": [
    "## Recommending the Top 50 Similar Subreddits\n",
    "\n",
    "Here, I am recommending the 50 most similar comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9963b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Method for getting top-n similar comments/titles\n",
    "def get_similar_posts(query, n):\n",
    "    \"\"\"\n",
    "    query (string): the text of the post\n",
    "    n (int): number of posts to recommend\n",
    "    \"\"\"\n",
    "    # Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "    top_k = min(n, len(corpus))\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "    similarities = []\n",
    "    pairs = []\n",
    "\n",
    "    # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, sarcasm_embeddings)[0]\n",
    "    top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop {n} most similar sentences in corpus:\".format(n=n))\n",
    "\n",
    "    for score, idx in zip(top_results[0], top_results[1]):\n",
    "#         print(corpus[idx], \"(Score: {:.4f})\".format(score))\n",
    "        pairs.append(tuple((corpus[idx], score)))\n",
    "    \n",
    "    recommend_frame = []\n",
    "    for val in pairs:\n",
    "        recommend_frame.append({'Comment':val[0],'Similarity':val[1].cpu().numpy()})\n",
    "     \n",
    "    df = pd.DataFrame(recommend_frame)\n",
    "    df = df.set_index(['Comment'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a990a83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Xbox is much better than PS4\n",
      "\n",
      "Top 50 most similar sentences in corpus:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No, because the xbox one is soooo much better than the ps4</th>\n",
       "      <td>0.9228309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>but xbox has the highest quality pixels, so it should be better than ps4, right?</th>\n",
       "      <td>0.88953227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xbox or PS4</th>\n",
       "      <td>0.8632204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ayy, better than Xbox 7 and PS5</th>\n",
       "      <td>0.8621861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ps4 or Xbox</th>\n",
       "      <td>0.8430183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Similarity\n",
       "Comment                                                       \n",
       "No, because the xbox one is soooo much better t...   0.9228309\n",
       "but xbox has the highest quality pixels, so it ...  0.88953227\n",
       "Xbox or PS4                                          0.8632204\n",
       "Ayy, better than Xbox 7 and PS5                      0.8621861\n",
       "Ps4 or Xbox                                          0.8430183"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_control = get_similar_posts('Xbox is much better than PS4', 50)\n",
    "df_control.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8550952c",
   "metadata": {},
   "source": [
    "## Calculating the Diversity\n",
    "\n",
    "The diversity of a set of items, c1,...cn, is defined as the average dissimilarity between all pairs of items in the result set.\n",
    "{add equation}\n",
    "\n",
    "Here, we can calculate the average dissimilarity of items recommended when no diversity algorithms are implemented. This will be used as a control to help us evaluate and compare our results later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcced92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059638280090020625"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 50\n",
    "dis_similarity = [x for x in pdist(df_control)]\n",
    "\n",
    "avg_dissim_control = (sum(dis_similarity))/((n/2)*(n-1))\n",
    "avg_dissim_control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095eb17c",
   "metadata": {},
   "source": [
    "## Bounded Greedy Selection Algorithm\n",
    "\n",
    "The Greedy Selection algorithm seeks to provide a more principled approach to improving diversity by using a quality metric to guide the construction of a result set, R, in an incremental fashion. During each iteration the remaining items are ordered according to their quality and the highest quality item added to R. The first item to be selected is always the one with the highest similarity to the target. During each subsequent iteration, the item selected is the one with the highest quality with respect to the set of cases selected during the previous iteration. This algorithm is expensive.\n",
    "\n",
    "To reduce the complexity of the Greedy Selection algorithm we can implement a bounded version. The Bounded Greedy Selection algorithm first selects the best x cases according to their similarity to the target query and then applies the greedy selection method to these. \n",
    "\n",
    "[Source](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.8.5232&rep=rep1&type=pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2e9705",
   "metadata": {},
   "source": [
    "### Step 1: Select the best x = 500 cases according to their similarity to the target query. Set C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd263296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Method for getting top-n similar comments/titles\n",
    "def get_similar_posts(query, n):\n",
    "    \"\"\"\n",
    "    query (string): the text of the post\n",
    "    n (int): number of posts to recommend\n",
    "    \"\"\"\n",
    "    # Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "    top_k = min(n, len(corpus))\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "    similarities = []\n",
    "    pairs = []\n",
    "\n",
    "    # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, sarcasm_embeddings)[0]\n",
    "    top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop {n} most similar sentences in corpus:\".format(n=n))\n",
    "\n",
    "    for score, idx in zip(top_results[0], top_results[1]):\n",
    "#         print(corpus[idx], \"(Score: {:.4f})\".format(score))\n",
    "        pairs.append(tuple((corpus[idx], score)))\n",
    "    \n",
    "    recommend_frame = []\n",
    "    for val in pairs:\n",
    "        recommend_frame.append({'Comment':val[0],'Similarity':val[1].cpu().numpy()})\n",
    "     \n",
    "    df = pd.DataFrame(recommend_frame)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "161af3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Xbox is much better than PS4\n",
      "\n",
      "Top 500 most similar sentences in corpus:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Similarity</th>\n",
       "      <th>label</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No, because the xbox one is soooo much better ...</td>\n",
       "      <td>0.9228309</td>\n",
       "      <td>1</td>\n",
       "      <td>awesome7332</td>\n",
       "      <td>gaming</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-06</td>\n",
       "      <td>2015-06-08 03:38:26</td>\n",
       "      <td>How about we stop arguing about the platforms.</td>\n",
       "      <td>[0.30111814, -0.6113374, 0.116583675, -0.63111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>but xbox has the highest quality pixels, so it...</td>\n",
       "      <td>0.88953227</td>\n",
       "      <td>1</td>\n",
       "      <td>its_high_knut</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-08</td>\n",
       "      <td>2016-08-09 20:20:45</td>\n",
       "      <td>They look even better if you play them on your...</td>\n",
       "      <td>[0.41256794, -0.464011, -0.2718223, -0.6063775...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xbox or PS4</td>\n",
       "      <td>0.8632204</td>\n",
       "      <td>0</td>\n",
       "      <td>DogblockBernie</td>\n",
       "      <td>Rainbow6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-09</td>\n",
       "      <td>2016-09-19 01:26:24</td>\n",
       "      <td>Same here!</td>\n",
       "      <td>[0.51289624, -0.74949, 0.08234843, -0.94248724...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ayy, better than Xbox 7 and PS5</td>\n",
       "      <td>0.8621861</td>\n",
       "      <td>1</td>\n",
       "      <td>DarkShadow1253</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-06</td>\n",
       "      <td>2015-06-15 17:59:29</td>\n",
       "      <td>To make you happy with your specs: YOUR SPECS ...</td>\n",
       "      <td>[0.083633505, -0.6993774, -0.01547823, -0.6487...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ps4 or Xbox</td>\n",
       "      <td>0.8430183</td>\n",
       "      <td>1</td>\n",
       "      <td>Karma_y0</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05</td>\n",
       "      <td>2016-05-21 21:37:44</td>\n",
       "      <td>If you could ask anyone on the internet someth...</td>\n",
       "      <td>[0.48774123, -0.7246228, 0.0145492, -0.9653652...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Similarity  label  \\\n",
       "0  No, because the xbox one is soooo much better ...   0.9228309      1   \n",
       "1  but xbox has the highest quality pixels, so it...  0.88953227      1   \n",
       "2                                        Xbox or PS4   0.8632204      0   \n",
       "3                    Ayy, better than Xbox 7 and PS5   0.8621861      1   \n",
       "4                                        Ps4 or Xbox   0.8430183      1   \n",
       "\n",
       "           author     subreddit  score  ups  downs     date  \\\n",
       "0     awesome7332        gaming      1    1      0  2015-06   \n",
       "1   its_high_knut  pcmasterrace      2    2      0  2016-08   \n",
       "2  DogblockBernie      Rainbow6      1    1      0  2016-09   \n",
       "3  DarkShadow1253  pcmasterrace      1    1      0  2015-06   \n",
       "4        Karma_y0     AskReddit      1    1      0  2016-05   \n",
       "\n",
       "           created_utc                                     parent_comment  \\\n",
       "0  2015-06-08 03:38:26     How about we stop arguing about the platforms.   \n",
       "1  2016-08-09 20:20:45  They look even better if you play them on your...   \n",
       "2  2016-09-19 01:26:24                                         Same here!   \n",
       "3  2015-06-15 17:59:29  To make you happy with your specs: YOUR SPECS ...   \n",
       "4  2016-05-21 21:37:44  If you could ask anyone on the internet someth...   \n",
       "\n",
       "                                              vector  \n",
       "0  [0.30111814, -0.6113374, 0.116583675, -0.63111...  \n",
       "1  [0.41256794, -0.464011, -0.2718223, -0.6063775...  \n",
       "2  [0.51289624, -0.74949, 0.08234843, -0.94248724...  \n",
       "3  [0.083633505, -0.6993774, -0.01547823, -0.6487...  \n",
       "4  [0.48774123, -0.7246228, 0.0145492, -0.9653652...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_prime = get_similar_posts('Xbox is much better than PS4', 500)\n",
    "C_prime = C_prime.join(df_m.set_index('comment'), on='Comment')\n",
    "C_prime.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befe07e3",
   "metadata": {},
   "source": [
    "### Step 2: Add the most similar item from C' as the first item in the result set R and drop this item from C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7195fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = C_prime\n",
    "recommendations = ['dummy']\n",
    "recommendations[0] = C_prime[\"Comment\"][0]  # first item is always the one with the highest similarity\n",
    "\n",
    "index = df_temp[(df_temp.Comment == recommendations[0])].index\n",
    "\n",
    "df_temp = df_temp.drop(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44895c9b",
   "metadata": {},
   "source": [
    "### Step 3: During each subsequent iteration, the item selected is the one with the highest quality with respect to the set of cases selected during the previous iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1c2bc6",
   "metadata": {},
   "source": [
    "The quality of an item c is proportional to the similarity between c and the current target t, and to the diversity of c relative to those items so far selected, R = {r1,...,rm}.\n",
    "\n",
    "Quality(t,c,R) = Similarity(t,c) ∗ RelDiversity(c,R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40cf626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def calculate_quality(c, R, df, df_sim):\n",
    "    quality = 0\n",
    "    rel_diversity = 0\n",
    "    \n",
    "    if len(R) == 0:\n",
    "        rel_diversity = 1\n",
    "        \n",
    "    vector = np.array(df['vector'][df['Comment'] == c].to_numpy()[0]).reshape(1, -1)\n",
    "    diversity = []\n",
    "    for item in R:\n",
    "        diversity.append(1 - cosine_similarity(vector, np.array(df_sim['vector'][df_sim['Comment'] == item].to_numpy()[0]).reshape(1, -1)))\n",
    "        \n",
    "    rel_diversity = sum(diversity)/len(R) # relative diversity\n",
    "    \n",
    "    similarity = df['Similarity'][df['Comment'] == c].to_numpy()[0] # similarity\n",
    "    \n",
    "    quality = rel_diversity[0][0] * similarity # quality\n",
    "    return quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c56a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set k = 50 to get top 50 recommendations\n",
    "k = 50\n",
    "for i in range(k):\n",
    "    qualities = {}\n",
    "    # Calculate the quality of each subreddit\n",
    "    for item in df_temp['Comment']:\n",
    "        qualities[item] = calculate_quality(item, recommendations, df_temp, C_prime)\n",
    "\n",
    "    highest_quality = max(qualities.values())\n",
    "    highest_quality_subreddit = max(qualities, key= lambda x: qualities[x])\n",
    "    recommendations.append(highest_quality_subreddit)\n",
    "    \n",
    "    index = df_temp[(df_temp.Comment == recommendations[-1])].index\n",
    "    df_temp = df_temp.drop(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fb15098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No, because the xbox one is soooo much better than the ps4',\n",
       " 'The best part is that Xbox gamers will play on separate servers to PC.',\n",
       " 'Tip: PSAs are better.',\n",
       " \"Omg no, I'm an investor and I'm sooooo disappointed in Xbox One not outselling PS4!\",\n",
       " 'Works fine on my PC, although I\\'d say the original Xbox 360 version is the \"best\"']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3a965d",
   "metadata": {},
   "source": [
    "## Evaluate the Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d94ad44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No, because the xbox one is soooo much better than the ps4</th>\n",
       "      <td>0.922831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The best part is that Xbox gamers will play on separate servers to PC.</th>\n",
       "      <td>0.578906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tip: PSAs are better.</th>\n",
       "      <td>0.599215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Omg no, I'm an investor and I'm sooooo disappointed in Xbox One not outselling PS4!</th>\n",
       "      <td>0.722312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Works fine on my PC, although I'd say the original Xbox 360 version is the \"best\"</th>\n",
       "      <td>0.686091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Similarity\n",
       "Comment                                                       \n",
       "No, because the xbox one is soooo much better t...    0.922831\n",
       "The best part is that Xbox gamers will play on ...    0.578906\n",
       "Tip: PSAs are better.                                 0.599215\n",
       "Omg no, I'm an investor and I'm sooooo disappoi...    0.722312\n",
       "Works fine on my PC, although I'd say the origi...    0.686091"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities = []\n",
    "for item in recommendations:\n",
    "    sim = C_prime['Similarity'][C_prime['Comment'] == item].to_numpy()[0]\n",
    "    similarities.append(sim)\n",
    "\n",
    "pairs = list(zip(recommendations, similarities))\n",
    "recommend_frame = []\n",
    "for val in pairs:\n",
    "    recommend_frame.append({'Comment':val[0],'Similarity':val[1].item(0)})    \n",
    "\n",
    "df_sim = pd.DataFrame(recommend_frame)\n",
    "df_sim = df_sim.set_index(['Comment'])\n",
    "df_sim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccd48ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07405671810617252"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the Diversity\n",
    "n = 50\n",
    "dis_similarity = [x for x in pdist(df_sim)]\n",
    "avg_dissim_greedy = (sum(dis_similarity))/((n/2)*(n-1))\n",
    "avg_dissim_greedy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a2edb9",
   "metadata": {},
   "source": [
    "## Compare Results to Normal RecSys\n",
    "\n",
    "We can compare the average dissimilarity of these new, diverse recommendations to our original ones in order to compare and evaluate the diversity in each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "772897a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.18"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_change = ((avg_dissim_greedy - avg_dissim_control)/avg_dissim_control)*100\n",
    "round(percent_change, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4924b504",
   "metadata": {},
   "source": [
    "Thus, there was a 24.2% increase in diversity (defined as average dissimilarity) when we move from a normal reccomendation system to a system that implements the Bounded Greedy Selection algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4bcc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "### END OF NOTEBOOK ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
