{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "becd69d3",
   "metadata": {},
   "source": [
    "# Total Diversity Effect (TDE) Ranking Recommendations\n",
    "\n",
    "This notebook implements the TDE Ranking Algorithm that was defined in the [Enhancing Diversity-Accuracy Technique on User-Based Top-N Recommendation Algorithms](https://sci-hub.se/https://ieeexplore.ieee.org/document/6605824/references#references) research paper. The dataset can be found [here](https://www.kaggle.com/timschaum/subreddit-recommender).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cd6d26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4070b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = pd.read_csv('../../civility/recommender/train-balanced-sarcasm-processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97b2ade4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all comments to a list\n",
    "corpus = df_m['comment'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bef85774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for computing embeddings:339.6262834072113\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "embedder = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Embed each comment\n",
    "import time\n",
    "start_time = time.time()\n",
    "sarcasm_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
    "end_time = time.time()\n",
    "print(\"Time for computing embeddings:\"+ str(end_time-start_time) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0c2fdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add vector embeddings as column in df\n",
    "vectors = []\n",
    "for vector in sarcasm_embeddings:\n",
    "    vectors.append(list(vector.cpu().numpy()))\n",
    "    \n",
    "df_m['vector'] = vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d58783",
   "metadata": {},
   "outputs": [],
   "source": [
    "#S-TDE Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1792ea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Generate a list of Top N+S recommendations (N between 3 and 10; S between 1 and 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d05c73a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Method for getting top-n similar comments\n",
    "def get_similar_posts(query, n):\n",
    "    \"\"\"\n",
    "    query (string): the text of the post\n",
    "    n (int): number of posts to recommend\n",
    "    \"\"\"\n",
    "    # Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "    top_k = min(n, len(corpus))\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "    similarities = []\n",
    "    pairs = []\n",
    "\n",
    "    # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, sarcasm_embeddings)[0]\n",
    "    top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop {n} most similar sentences in corpus:\".format(n=n))\n",
    "\n",
    "    for score, idx in zip(top_results[0], top_results[1]):\n",
    "        pairs.append(tuple((corpus[idx], score)))\n",
    "    \n",
    "    recommend_frame = []\n",
    "    for val in pairs:\n",
    "        recommend_frame.append({'Comment':val[0],'Similarity':val[1].cpu().numpy()})\n",
    "     \n",
    "    df = pd.DataFrame(recommend_frame)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bfbc3b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Obama is NOT american\n",
      "\n",
      "Top 15 most similar sentences in corpus:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Similarity</th>\n",
       "      <th>label</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Let's not forget Obama's not American.</td>\n",
       "      <td>0.797965</td>\n",
       "      <td>1</td>\n",
       "      <td>wiseaus_stunt_double</td>\n",
       "      <td>hockey</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-07</td>\n",
       "      <td>2014-07-06 19:00:47</td>\n",
       "      <td>Look, not to be a homer, but I legitimately wo...</td>\n",
       "      <td>[0.43582183, 0.07268912, -0.31050923, -0.63595...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He isn't American</td>\n",
       "      <td>0.76655585</td>\n",
       "      <td>0</td>\n",
       "      <td>justafanpassingby</td>\n",
       "      <td>soccer</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-06</td>\n",
       "      <td>2016-06-14 05:32:20</td>\n",
       "      <td>You sound like someone who believes the moon l...</td>\n",
       "      <td>[0.54248154, -0.18107486, 0.119683914, -0.6661...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not Obama?</td>\n",
       "      <td>0.7615357</td>\n",
       "      <td>1</td>\n",
       "      <td>ijustwantanfingname</td>\n",
       "      <td>technology</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-04</td>\n",
       "      <td>2013-04-21 05:06:27</td>\n",
       "      <td>Because politicians never lie... Right?</td>\n",
       "      <td>[0.3969663, 0.40757543, 0.10303464, -0.6554833...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Well we got Obama and he's not american born</td>\n",
       "      <td>0.75621384</td>\n",
       "      <td>1</td>\n",
       "      <td>pajepper_kepper</td>\n",
       "      <td>Futurology</td>\n",
       "      <td>58</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-11</td>\n",
       "      <td>2016-11-23 18:28:19</td>\n",
       "      <td>can't. Not born in the US South African-born</td>\n",
       "      <td>[0.41099304, 0.31186214, -0.24328573, -0.22447...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>That's not Obama</td>\n",
       "      <td>0.7377236</td>\n",
       "      <td>1</td>\n",
       "      <td>Chuew12345</td>\n",
       "      <td>pics</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-10</td>\n",
       "      <td>2015-10-15 02:53:33</td>\n",
       "      <td>Selfie with the president</td>\n",
       "      <td>[0.13465954, -0.08795648, -0.069007166, -0.425...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Comment  Similarity  label  \\\n",
       "0        Let's not forget Obama's not American.    0.797965      1   \n",
       "1                             He isn't American  0.76655585      0   \n",
       "2                                    Not Obama?   0.7615357      1   \n",
       "3  Well we got Obama and he's not american born  0.75621384      1   \n",
       "4                              That's not Obama   0.7377236      1   \n",
       "\n",
       "                 author   subreddit  score  ups  downs     date  \\\n",
       "0  wiseaus_stunt_double      hockey      5    5      0  2014-07   \n",
       "1     justafanpassingby      soccer      1    1      0  2016-06   \n",
       "2   ijustwantanfingname  technology      1    1      0  2013-04   \n",
       "3       pajepper_kepper  Futurology     58   -1     -1  2016-11   \n",
       "4            Chuew12345        pics      1    1      0  2015-10   \n",
       "\n",
       "           created_utc                                     parent_comment  \\\n",
       "0  2014-07-06 19:00:47  Look, not to be a homer, but I legitimately wo...   \n",
       "1  2016-06-14 05:32:20  You sound like someone who believes the moon l...   \n",
       "2  2013-04-21 05:06:27            Because politicians never lie... Right?   \n",
       "3  2016-11-23 18:28:19       can't. Not born in the US South African-born   \n",
       "4  2015-10-15 02:53:33                          Selfie with the president   \n",
       "\n",
       "                                              vector  \n",
       "0  [0.43582183, 0.07268912, -0.31050923, -0.63595...  \n",
       "1  [0.54248154, -0.18107486, 0.119683914, -0.6661...  \n",
       "2  [0.3969663, 0.40757543, 0.10303464, -0.6554833...  \n",
       "3  [0.41099304, 0.31186214, -0.24328573, -0.22447...  \n",
       "4  [0.13465954, -0.08795648, -0.069007166, -0.425...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 10\n",
    "S = 5\n",
    "C_prime = get_similar_posts('Obama is NOT american', N+S)\n",
    "C_prime = C_prime.join(df_m.set_index('comment'), on='Comment')\n",
    "C_prime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4a9c8c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Calculate the TDE of each item as the sum of distances to all other (N+S-1) items on the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "10f32a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "df_distance = C_prime.copy()\n",
    "TDE = {}\n",
    "vectors = C_prime['vector'].to_list()\n",
    "\n",
    "for i, vector in enumerate(vectors):\n",
    "    other_vectors = C_prime['vector'].to_list()\n",
    "    other_vectors.remove(vector)\n",
    "    TDE[i] = 0\n",
    "    for vec in other_vectors:\n",
    "        TDE[i] += distance.euclidean(vector, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0a33b8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Remove S items with the lowest TDE score and so generate the Top N recommendations for the current user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2ba40c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TDE = dict(sorted(TDE.items(), key=lambda item: item[1], reverse=True))\n",
    "for i in range(S):\n",
    "    TDE.popitem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4bc4cc17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{9: 104.47456359863281,\n",
       " 14: 103.1512565612793,\n",
       " 5: 101.95061302185059,\n",
       " 7: 96.00982570648193,\n",
       " 12: 92.7237057685852,\n",
       " 8: 92.31631851196289,\n",
       " 13: 91.66197776794434,\n",
       " 2: 91.14478778839111,\n",
       " 6: 88.89259362220764,\n",
       " 4: 87.38392210006714}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6fb6833b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Not Obama?</th>\n",
       "      <td>0.7615357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>That's not Obama</th>\n",
       "      <td>0.7377236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obama is American..?</th>\n",
       "      <td>0.7302852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>He must not be American</th>\n",
       "      <td>0.72961265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obama is not a real human being</th>\n",
       "      <td>0.72588533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not according to Obama...</th>\n",
       "      <td>0.70943683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American is not a race</th>\n",
       "      <td>0.69935656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not being American.</th>\n",
       "      <td>0.6946306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Didn't Obama say that too</th>\n",
       "      <td>0.69011813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Why does Obama hate America?</th>\n",
       "      <td>0.6882608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Similarity\n",
       "Comment                                    \n",
       "Not Obama?                        0.7615357\n",
       "That's not Obama                  0.7377236\n",
       "Obama is American..?              0.7302852\n",
       "He must not be American          0.72961265\n",
       "Obama is not a real human being  0.72588533\n",
       "Not according to Obama...        0.70943683\n",
       "American is not a race           0.69935656\n",
       "Not being American.               0.6946306\n",
       "Didn't Obama say that too        0.69011813\n",
       "Why does Obama hate America?      0.6882608"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for entry in C_prime.index:\n",
    "    if entry in TDE.keys():\n",
    "        result.append({'Comment': C_prime[\"Comment\"].iloc[entry], 'Similarity': C_prime[\"Similarity\"].iloc[entry]})\n",
    "        \n",
    "df = pd.DataFrame(result)\n",
    "df = df.set_index(['Comment'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "36f8d001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028404492802090116"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "dis_similarity = [x for x in pdist(df)]\n",
    "total_dissim_TDE = sum(dis_similarity)/((n)*((n-1)/2))\n",
    "total_dissim_TDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "adfab6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Method for getting top-n similar comments/titles\n",
    "def get_similar_posts(query, n):\n",
    "    \"\"\"\n",
    "    query (string): the text of the post\n",
    "    n (int): number of posts to recommend\n",
    "    \"\"\"\n",
    "    # Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "    top_k = min(n, len(corpus))\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "    similarities = []\n",
    "    pairs = []\n",
    "\n",
    "    # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, sarcasm_embeddings)[0]\n",
    "    top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop {n} most similar sentences in corpus:\".format(n=n))\n",
    "\n",
    "    for score, idx in zip(top_results[0], top_results[1]):\n",
    "        pairs.append(tuple((corpus[idx], score)))\n",
    "    \n",
    "    recommend_frame = []\n",
    "    for val in pairs:\n",
    "        recommend_frame.append({'Comment':val[0],'Similarity':val[1].cpu().numpy()})\n",
    "     \n",
    "    df = pd.DataFrame(recommend_frame)\n",
    "    df = df.set_index(['Comment'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fbac6d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Obama is NOT american\n",
      "\n",
      "Top 10 most similar sentences in corpus:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Let's not forget Obama's not American.</th>\n",
       "      <td>0.797965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>He isn't American</th>\n",
       "      <td>0.76655585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not Obama?</th>\n",
       "      <td>0.7615357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Well we got Obama and he's not american born</th>\n",
       "      <td>0.75621384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>That's not Obama</th>\n",
       "      <td>0.7377236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obama is American..?</th>\n",
       "      <td>0.7302852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>He must not be American</th>\n",
       "      <td>0.72961265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obama is not a real human being</th>\n",
       "      <td>0.72588533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not according to Obama...</th>\n",
       "      <td>0.70943683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American is not a race</th>\n",
       "      <td>0.69935656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Similarity\n",
       "Comment                                                 \n",
       "Let's not forget Obama's not American.          0.797965\n",
       "He isn't American                             0.76655585\n",
       "Not Obama?                                     0.7615357\n",
       "Well we got Obama and he's not american born  0.75621384\n",
       "That's not Obama                               0.7377236\n",
       "Obama is American..?                           0.7302852\n",
       "He must not be American                       0.72961265\n",
       "Obama is not a real human being               0.72588533\n",
       "Not according to Obama...                     0.70943683\n",
       "American is not a race                        0.69935656"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_control = get_similar_posts('Obama is NOT american', 10)\n",
    "df_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "32ac1790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034506728914048934"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "dis_similarity = [x for x in pdist(df_control)]\n",
    "\n",
    "total_dissim_control = sum(dis_similarity)/((n)*((n-1)/2))\n",
    "total_dissim_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "75d0ef4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-17.68"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_change = ((total_dissim_TDE - total_dissim_control)/total_dissim_control)*100\n",
    "round(percent_change, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa3019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### END OF NOTEBOOK ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
